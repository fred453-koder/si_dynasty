import feedparser
import time
import openai
import tldextract
import re
from datetime import datetime, timedelta
from telegram import Bot
import os

# === –ù–ê–°–¢–†–û–ô–ö–ò ===
TELEGRAM_TOKEN = "7725055774:AAHRf_3tfVO-ZufWBZZpTT92P5WQS5GRoUQ"
CHANNEL_ID = "@xi_dynasty"
OPENAI_API_KEY = "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"

POSTED_LINKS_FILE = "posted_links.txt"

RSS_FEEDS = [
    "http://www.xinhuanet.com/english/rss/worldrss.xml",
    "http://www.chinadaily.com.cn/rss/china_rss.xml",
    "https://www.scmp.com/rss/91/feed",
    "https://www.fmprc.gov.cn/mfa_eng/rss.xml",
    "https://thediplomat.com/feed/",
    "https://www.asiapacificsecuritymagazine.com/feed/",
    "https://www.indiatoday.in/rss/1206514",
    "https://eastasiaforum.org/feed/",
    "https://venturebeat.com/category/ai/feed/"
]

KEYWORDS = [
    "China", "Beijing", "Taiwan", "Xi Jinping", "PLA", "Chinese military",
    "AI", "artificial intelligence", "drones", "semiconductors",
    "Silk Road", "BRI", "space program", "spy balloon", "trade war", "sanctions",
    "army", "tariffs", "USA", "Ukraine", "Zelensky", "Putin", "Moscow",
    "war", "deal", "business", "investments", "condemned", "official visit",
    "Taiwan", "oil", "gas", "yuan", "Indo-Pacific", "ASEAN", "Blinken",
    "Biden", "South China Sea", "diplomacy", "Philippines", "maritime", "nuclear"
]

EXCLUDE_PATTERNS = [
    "crash", "accident", "injured", "fire", "killed", "police", "arrested",
    "dies", "dead", "murder", "suicide", "hospital"
]

bot = Bot(token=TELEGRAM_TOKEN)
openai.api_key = OPENAI_API_KEY

def send_message_safe(text):
    try:
        bot.send_message(
            chat_id=CHANNEL_ID,
            text=text,
            parse_mode='HTML',
            disable_web_page_preview=True,
            timeout=20
        )
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Telegram: {e}")

def extract_source(url):
    ext = tldextract.extract(url)
    if ext.domain == "scmp":
        return "South China Morning Post"
    return ext.domain.capitalize()

def rewrite_news(title, summary, source):
    prompt = f"""
–¢–∏ –ø—Ä–∞—Ü—é—î—à —è–∫ –∫–æ–º–∞–Ω–¥–∞ –∑ —Ç—Ä—å–æ—Ö –ø—Ä–æ—Ñ–µ—Å—ñ–æ–Ω–∞–ª—ñ–≤:
1. –∂—É—Ä–Ω–∞–ª—ñ—Å—Ç ‚Äî –≤–∏–∫–ª–∞–¥–∞—î —Å—É—Ç—å –ø–æ–¥—ñ–π;
2. –∞–Ω–∞–ª—ñ—Ç–∏–∫ ‚Äî —Ñ–æ—Ä–º—É–ª—é—î –∫–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ–≥–Ω–æ–∑;
3. —Ä–µ–¥–∞–∫—Ç–æ—Ä-–ø–µ—Ä–µ–∫–ª–∞–¥–∞—á ‚Äî –∞–¥–∞–ø—Ç—É—î —Ç–µ–∫—Å—Ç —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –±–µ–∑ —Å—É—Ä–∂–∏–∫—É —ñ –∫–∞–ª—å–∫–∏.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å—Ç–≤–æ—Ä–∏—Ç–∏ –ø–æ—Å—Ç –¥–ª—è –∞–Ω–∞–ª—ñ—Ç–∏—á–Ω–æ–≥–æ Telegram-–∫–∞–Ω–∞–ª—É –ø—Ä–æ –≥–µ–æ–ø–æ–ª—ñ—Ç–∏–∫—É –ö–∏—Ç–∞—é. –Ø–∫—â–æ –¥–∂–µ—Ä–µ–ª–æ ‚Äî —Ü–µ –ø—É–±–ª—ñ—Ü–∏—Å—Ç–∏–∫–∞ –∞–±–æ –∫–æ–ª–æ–Ω–∫–∞, –ø–µ—Ä–µ—Ä–æ–±–∏ —ó—ó –≤ –∫–æ—Ä–æ—Ç–∫–∏–π –≤–∏–∫–ª–∞–¥ —ñ –¥–æ–¥–∞–π –ø—Ä–æ–≥–Ω–æ–∑. –Ø–∫—â–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è —Å–ª–∞–±–∫–∞ –∞–±–æ –≤—Ç–æ—Ä–∏–Ω–Ω–∞ ‚Äî –∫—Ä–∞—â–µ –Ω—ñ—á–æ–≥–æ –Ω–µ –ø–∏—à–∏.

üìå –§–æ—Ä–º–∞—Ç:
1. <b>–ñ–∏—Ä–Ω–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫</b>
2. –ü–µ—Ä—à–∏–π –∞–±–∑–∞—Ü ‚Äî –≤–∏–∫–ª–∞–¥ –ø–æ–¥—ñ–π
3. –î—Ä—É–≥–∏–π –∞–±–∑–∞—Ü ‚Äî –∞–Ω–∞–ª—ñ—Ç–∏—á–Ω–µ –ø–æ—è—Å–Ω–µ–Ω–Ω—è
4. <b>–ü—Ä–æ–≥–Ω–æ–∑:</b> —É –≤–∏–≥–ª—è–¥—ñ –∞–±–∑–∞—Ü—É, –±–µ–∑ —Ç–µ–≥–∞ <code>
5. <i>–¶–∏—Ç–∞—Ç–∞ –∫–∏—Ç–∞–π—Å—å–∫–æ–≥–æ –º–∏—Å–ª–∏—Ç–µ–ª—è</i> ‚Äî –∑ —ñ–º–µ–Ω–µ–º –∞–≤—Ç–æ—Ä–∞
6. ‚Äú–ü—ñ–¥–ø–∏—Å—É–π—Å—è –Ω–∞ –î–∏–Ω–∞—Å—Ç—ñ—é üõ∏‚Äù
7. üìå –î–∂–µ—Ä–µ–ª–æ: {source}

‚úçÔ∏è –û–±–æ–≤'—è–∑–∫–æ–≤–æ:
- –ö–æ–∂–Ω–µ —Ä–µ—á–µ–Ω–Ω—è ‚Äî –Ω–µ –¥–æ–≤—à–µ 14 —Å–ª—ñ–≤.
- –£–Ω–∏–∫–∞–π —Å–∫–ª–∞–¥–Ω–æ–ø—ñ–¥—Ä—è–¥–Ω–∏—Ö —Ä–µ—á–µ–Ω—å —ñ –∫–∞–Ω—Ü–µ–ª—è—Ä–∏–∑–º—ñ–≤.
- –ü–µ—Ä–µ–≤—ñ—Ä—è–π –ø—Ä–∞–≤–∏–ª—å–Ω—ñ—Å—Ç—å –≤—ñ–¥–º—ñ–Ω–∫—ñ–≤.
- –ù–µ –¥–æ–¥–∞–≤–∞–π –∑–∞–π–≤–æ–≥–æ –ø–∞—Ñ–æ—Å—É. –ü–∏—à–∏ –ª–∞–∫–æ–Ω—ñ—á–Ω–æ, —Å–∏–ª—å–Ω–æ —ñ —Å–º–∞—á–Ω–æ.
- –Ø–∫—â–æ —Ü–µ –∞–≤—Ç–æ—Ä—Å—å–∫–∞ –∫–æ–ª–æ–Ω–∫–∞ ‚Äî –∑–≥–∞–¥–∞–π –∞–≤—Ç–æ—Ä–∞ —É –¥—Ä—É–≥–æ–º—É –∞–±–∑–∞—Ü—ñ.
- –î—ñ–ª–∏ —Å–∫–ª–∞–¥–Ω—ñ —Ä–µ—á–µ–Ω–Ω—è –Ω–∞ –¥–≤–∞. –ù–µ –±—ñ–π—Å—è –∫—Ä–∞–ø–æ–∫.

–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}
–û–ø–∏—Å: {summary}
"""

    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "–¢–∏ –ø—Ä–∞—Ü—é—î—à —è–∫ –∫–æ–º–∞–Ω–¥–∞ –∂—É—Ä–Ω–∞–ª—ñ—Å—Ç–∞, –∞–Ω–∞–ª—ñ—Ç–∏–∫–∞ —ñ —Ä–µ–¥–∞–∫—Ç–æ—Ä–∞. –°—Ç–≤–æ—Ä—é—î—à —Å—Ç—Ä–∞—Ç–µ–≥—ñ—á–Ω—ñ –ø—É–±–ª—ñ–∫–∞—Ü—ñ—ó –¥–ª—è –∞–Ω–∞–ª—ñ—Ç–∏—á–Ω–æ–≥–æ Telegram-–∫–∞–Ω–∞–ª—É –ø—Ä–æ –ö–∏—Ç–∞–π. –í–º—ñ—î—à –≤—ñ–¥—Ä—ñ–∑–Ω—è—Ç–∏ –Ω–æ–≤–∏–Ω—É –≤—ñ–¥ –ø—É–±–ª—ñ—Ü–∏—Å—Ç–∏–∫–∏ —ñ –Ω–µ –≤–∏–≥–∞–¥—É—î—à —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é."},
            {"role": "user", "content": prompt}
        ]
    )

    return response.choices[0].message.content.strip().replace("–†—ñ–¥–ø–∏—à–∏—Å—å", "–ü—ñ–¥–ø–∏—à–∏—Å—å")

def load_posted_links():
    if not os.path.exists(POSTED_LINKS_FILE):
        return set()
    with open(POSTED_LINKS_FILE, "r") as f:
        return set(line.strip() for line in f)

def save_posted_link(link):
    with open(POSTED_LINKS_FILE, "a") as f:
        f.write(link + "\n")

if __name__ == "__main__":
    print("–°–∫—Ä–∏–ø—Ç –∑–∞–ø—É—â–µ–Ω ‚Äî –ø–æ—á–∏–Ω–∞—î–º–æ –æ–±—Ä–æ–±–∫—É RSS")
    posted_links = load_posted_links()

    for feed_url in RSS_FEEDS:
        print(f"–ü–æ—Ç—ñ–∫: {feed_url}")
        feed = feedparser.parse(feed_url)

        for entry in feed.entries[:10]:
            if not hasattr(entry, 'published_parsed'):
                print(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ: –Ω–µ–º–∞—î –¥–∞—Ç–∏ ‚Äî {entry.get('title', '')}")
                continue

            published = datetime.fromtimestamp(time.mktime(entry.published_parsed))
            if datetime.now() - published > timedelta(hours=96):
                print(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ: —Å—Ç–∞—Ä–∞ –Ω–æ–≤–∏–Ω–∞ ‚Äî {entry.get('title', '')}")
                continue

            title = entry.get("title", "[–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞]")
            summary = re.sub('<[^<]+?>', '', entry.get("summary", ""))
            link = entry.get("link", "[–ë–µ–∑ –ø–æ—Å–∏–ª–∞–Ω–Ω—è]")

            if link in posted_links:
                print(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ: –≤–∂–µ –±—É–ª–æ ‚Äî {title}")
                continue

            combined_text = f"{title} {summary}".lower()

            if not any(keyword.lower() in combined_text for keyword in KEYWORDS):
                print(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ: –Ω–µ –ø–æ –∫–ª—é—á–æ–≤–∏–º —Å–ª–æ–≤–∞–º ‚Äî {title}")
                continue

            if any(pattern in combined_text for pattern in EXCLUDE_PATTERNS):
                print(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ: –ø–æ–±—É—Ç/–î–¢–ü ‚Äî {title}")
                continue

            print(f"[OK] {title}\n{link}\n")

            source = extract_source(link)
            rewritten = rewrite_news(title, summary, source)
            send_message_safe(rewritten)
            save_posted_link(link)

        time.sleep(1)
